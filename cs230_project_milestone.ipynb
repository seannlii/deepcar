{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from keras import layers, models\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "#from keras.applications.imagenet_utils import preprocess_input\n",
    "#import pydot\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "#from kt_utils import *\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "import os\n",
    "import datetime\n",
    "import math\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "import multiprocessing as mp\n",
    "mp.set_start_method('spawn', force=True)\n",
    "\n",
    "modelToLoad = \"InceptionV3\"\n",
    "\n",
    "if modelToLoad == \"VGG\":\n",
    "    from keras.applications.vgg19 import VGG19\n",
    "    from keras.applications.vgg19 import preprocess_input\n",
    "elif modelToLoad == \"ResNet50\":\n",
    "    from keras.applications import ResNet50\n",
    "    from keras.applications.ResNet50 import preprocess_input\n",
    "elif modelToLoad == \"InceptionV3\":\n",
    "    from keras.applications import InceptionV3\n",
    "    from keras.applications.inception_v3 import preprocess_input\n",
    "else:\n",
    "    print(\"error\")\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#to restart GPU to clear memory, run this and then restart kernel\n",
    "from numba import cuda\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n",
    "# #to limit tf's memory usage\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=12288)])\n",
    "\n",
    "\n",
    "print(\"loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if modelToLoad == \"VGG\":\n",
    "    image_size_h = 224 #382\n",
    "    image_size_w = 224 #512\n",
    "elif modelToLoad == \"InceptionV3\":\n",
    "    image_size_h = 299 #382\n",
    "    image_size_w = 299 #512\n",
    "else:\n",
    "    print(\"using MEAN dimensions of dataset\")\n",
    "    image_size_h = 382\n",
    "    image_size_w = 512\n",
    "    \n",
    "train_batch_size = 32\n",
    "dev_batch_size = 32\n",
    "test_batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "includePreTrained = True #include pretrained model in the final model for training\n",
    "setToUse = \"full\"\n",
    "\n",
    "if setToUse == \"mini\":    \n",
    "    train_path = \"C:\\\\Users\\\\Sean\\\\Downloads\\\\cs230_jupyter\\\\VMMRdb_mini\\\\train\"\n",
    "    dev_path = 'C:\\\\Users\\\\Sean\\\\Downloads\\\\cs230_jupyter\\\\VMMRdb_mini\\\\dev'\n",
    "    test_path = 'C:\\\\Users\\\\Sean\\\\Downloads\\\\cs230_jupyter\\\\VMMRdb_mini\\\\test'\n",
    "    bottleneck_file_root = \"D:\\\\Debian\\\\cs_230_proj\\\\bottleneck\\\\inceptionv3\\\\\"\n",
    "    #\"D:\\\\Debian\\\\cs_230_proj\\\\bottleneck\\\\\"\n",
    "\n",
    "elif setToUse == \"full\":    \n",
    "    train_path = \"D:/Debian/cs_230_proj/VMMRdb_year2000+_sample100+/train\"\n",
    "    dev_path = \"D:/Debian/cs_230_proj/VMMRdb_year2000+_sample100+/dev\"\n",
    "    test_path = \"D:/Debian/cs_230_proj/VMMRdb_year2000+_sample100+/test\"\n",
    "    bottleneck_file_root = \"D:/Debian/cs_230_proj/VMMRdb_year2000+_sample100+/inceptionv3_fulldata/\"\n",
    "\n",
    "elif setToUse == \"mini_new\":    \n",
    "    train_path = \"D:/Debian/cs_230_proj/VMMRdb_mini_new/train\"\n",
    "    dev_path = \"D:/Debian/cs_230_proj/VMMRdb_mini_new/dev\"\n",
    "    test_path = \"D:/Debian/cs_230_proj/VMMRdb_mini_new/test\"\n",
    "    bottleneck_file_root = \"D:/Debian/cs_230_proj/VMMRdb_mini_new/inceptionv3_fulldata/\"    \n",
    "\n",
    "top_model_weights_path = \"D:/Debian/cs_230_proj/inceptionv3_model.h5\"\n",
    "\n",
    "# datagen_train = ImageDataGenerator(rescale=1. / 255) \n",
    "# datagen_dev = ImageDataGenerator(rescale=1. / 255) \n",
    "# datagen_test = ImageDataGenerator(rescale=1. / 255) \n",
    "\n",
    "# datagen_train = ImageDataGenerator(preprocessing_function = preprocess_input) \n",
    "datagen_dev = ImageDataGenerator(preprocessing_function = preprocess_input) \n",
    "datagen_test = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "datagen_train = ImageDataGenerator(preprocessing_function = preprocess_input,\n",
    "                                    rotation_range=8, \n",
    "                                    width_shift_range=0.08, \n",
    "                                    height_shift_range=0.08,\n",
    "                                    shear_range=0.10, \n",
    "                                    zoom_range=0.08,\n",
    "                                    channel_shift_range = 10, \n",
    "                                    horizontal_flip=True,\n",
    "                                    fill_mode=\"constant\") \n",
    "# datagen_dev = ImageDataGenerator(preprocessing_function = preprocess_input,\n",
    "#                                     rotation_range=10, \n",
    "#                                     width_shift_range=0.1, \n",
    "#                                     height_shift_range=0.1,\n",
    "#                                     shear_range=0.15, \n",
    "#                                     zoom_range=0.1,\n",
    "#                                     channel_shift_range = 10, \n",
    "#                                     horizontal_flip=True,\n",
    "#                                     fill_mode=\"nearest\")                                 \n",
    "# datagen_test = ImageDataGenerator(preprocessing_function = preprocess_input,\n",
    "#                                     rotation_range=10, \n",
    "#                                     width_shift_range=0.1, \n",
    "#                                     height_shift_range=0.1,\n",
    "#                                     shear_range=0.15, \n",
    "#                                     zoom_range=0.1,\n",
    "#                                     channel_shift_range = 10, \n",
    "#                                     horizontal_flip=True,\n",
    "#                                     fill_mode=\"nearest\")                                   \n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#####################################\n",
    "##NO NEED TO RUN EVERY SINGLE TIME ##\n",
    "#####################################\n",
    "#To send input images through the frozen part of the network and cache the results, which would be\n",
    "#used as input for training. This would improve training speed significantly \n",
    "vgg = InceptionV3(include_top=False, weights=\"imagenet\",input_shape=(image_size_w, image_size_h, 3))\n",
    "\n",
    "# #To pop last few layers\n",
    "# vgg.layers.pop()\n",
    "# vgg.layers.pop()\n",
    "# vgg.layers.pop()\n",
    "# vgg.layers.pop()\n",
    "# vgg.layers.pop()\n",
    "\n",
    "\n",
    "##TRAIN SET\n",
    "#__this can take an hour and half to run so only run it once. \n",
    "#once the npy files have been created, no need to run again. Convert this cell to a code cell to run.__\n",
    "start = datetime.datetime.now()\n",
    " \n",
    "generator_train = datagen_train.flow_from_directory( \n",
    "    train_path, \n",
    "    target_size=(image_size_w, image_size_h), \n",
    "    batch_size=train_batch_size, \n",
    "    class_mode=None, \n",
    "    shuffle=True) \n",
    " \n",
    "nb_train_samples = len(generator_train.filenames) \n",
    "num_classes = len(generator_train.class_indices) \n",
    " \n",
    "predict_size_train = int(math.ceil(nb_train_samples / train_batch_size)) \n",
    "\n",
    "if includePreTrained == False:\n",
    "    bottleneck_features_train = vgg.predict_generator(generator_train, predict_size_train, verbose=1) \n",
    "\n",
    "    np.save(bottleneck_file_root+\"bottleneck_features_train.npy\", bottleneck_features_train)\n",
    "    end= datetime.datetime.now()\n",
    "    elapsed= end-start\n",
    "    print (\"Time: \", elapsed)\n",
    "    \n",
    "# else:\n",
    "#     prediction_proba1=[]\n",
    "#     prediction_classes1=[]\n",
    "#     print(\"generator_train len: \", len(generator_train))\n",
    "# #     print(\"generator_dev: \", len(validation_generator))\n",
    "# #     print(\"generator_test: \", len(validation_generator))\n",
    "#     for i in range(len(generator_train)):\n",
    "#         print (\" array coming...\")\n",
    "#         #print(validation_generator[i])\n",
    "#         kl = generator_train[i]\n",
    "# #         print(kl)\n",
    "#         print(\"numpy array\")\n",
    "#         print(kl.shape)\n",
    "#         #print(kl[0])\n",
    "#         features = vgg.predict_on_batch(kl)\n",
    "#         print(\"features\")\n",
    "#         print(features)\n",
    "#         prediction_proba = vgg.predict_proba(features)\n",
    "#         prediction_classes = vgg.predict_classes(features)\n",
    "#         prediction_classes1.extend(prediction_classes)\n",
    "#         prediction_proba1.extend(prediction_proba)\n",
    "#         #print(prediction_proba1)\n",
    "#         print(prediction_classes1)\n",
    "\n",
    "##DEV SET\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "generator_dev = datagen_dev.flow_from_directory( \n",
    "    dev_path, \n",
    "    target_size=(image_size_w, image_size_h), \n",
    "    batch_size=dev_batch_size, \n",
    "    class_mode=None, \n",
    "    shuffle=True) \n",
    " \n",
    "nb_dev_samples = len(generator_dev.filenames) \n",
    "num_classes = len(generator_dev.class_indices) \n",
    " \n",
    "predict_size_dev = int(math.ceil(nb_dev_samples / dev_batch_size)) \n",
    "\n",
    "if includePreTrained == False:\n",
    "    bottleneck_features_dev = vgg.predict_generator(generator_dev, predict_size_dev) \n",
    "\n",
    "    np.save(bottleneck_file_root+\"bottleneck_features_dev.npy\", bottleneck_features_dev)\n",
    "    end = datetime.datetime.now()\n",
    "    print(\"Time: \", end-start)\n",
    "\n",
    "##TEST SET\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "\n",
    "generator_test = datagen_test.flow_from_directory( \n",
    "    test_path, \n",
    "    target_size=(image_size_w, image_size_h), \n",
    "    batch_size=test_batch_size, \n",
    "    class_mode=None, \n",
    "    shuffle=True) \n",
    " \n",
    "nb_test_samples = len(generator_test.filenames) \n",
    "num_classes_ = len(generator_test.class_indices) \n",
    " \n",
    "predict_size_test = int(math.ceil(nb_test_samples / test_batch_size)) \n",
    "\n",
    "if (includePreTrained == False):\n",
    "    bottleneck_features_test = vgg.predict_generator(generator_test, predict_size_test) \n",
    "\n",
    "    np.save(bottleneck_file_root+\"bottleneck_features_test.npy\", bottleneck_features_test)\n",
    "    end = datetime.datetime.now()\n",
    "    print(\"Time: \", end-start)\n",
    "\n",
    "# i=0\n",
    "# for batch in generator_train:\n",
    "#     i+=1\n",
    "#     if i > 0: #save 2-1 = one image\n",
    "#         break  # otherwise the generator would loop indefinitely\n",
    "# i=0\n",
    "# for batch in generator_dev:\n",
    "#     i+=1\n",
    "#     if i > 0: #save 2-1 = one image\n",
    "#         break  # otherwise the generator would loop indefinitely\n",
    "# i=0\n",
    "# for batch in generator_test:\n",
    "#     i+=1\n",
    "#     if i > 0: #save 2-1 = one image\n",
    "#         break  # otherwise the generator would loop indefinitely\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Loading Training Input Data from cache\n",
    "#training data\n",
    "generator_top = datagen_train.flow_from_directory( \n",
    "   train_path, \n",
    "   target_size=(image_size_w, image_size_h), \n",
    "   batch_size=train_batch_size, \n",
    "   class_mode=\"categorical\", \n",
    "   shuffle=True) \n",
    "\n",
    "nb_train_samples = len(generator_top.filenames) \n",
    "num_classes = len(generator_top.class_indices) \n",
    " \n",
    " \n",
    " \n",
    "# get the class labels for the training data, in the original order \n",
    "train_labels = generator_top.classes \n",
    "# convert the training labels to categorical vectors \n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "\n",
    "#class_weight for imbalanced classes\n",
    "counter = Counter(generator_top.classes)                          \n",
    "max_val = float(max(counter.values()))       \n",
    "class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}                     \n",
    "\n",
    "print(class_weights)\n",
    "\n",
    "#validation data\n",
    "generator_top_dev = datagen_dev.flow_from_directory( \n",
    "   dev_path, \n",
    "   target_size=(image_size_w, image_size_h), \n",
    "   batch_size=dev_batch_size, \n",
    "   class_mode=\"categorical\", #none??\n",
    "   shuffle=True) \n",
    "\n",
    "nb_dev_samples = len(generator_top_dev.filenames) \n",
    "num_classes_dev = len(generator_top_dev.class_indices) \n",
    "\n",
    "\n",
    " \n",
    "dev_labels = generator_top_dev.classes \n",
    " \n",
    "dev_labels = to_categorical(dev_labels, num_classes=num_classes_dev)\n",
    "\n",
    "#test data\n",
    "generator_top_test = datagen_test.flow_from_directory( \n",
    "   test_path, \n",
    "   target_size=(image_size_w, image_size_h), \n",
    "   batch_size=test_batch_size, \n",
    "   class_mode=\"categorical\", \n",
    "   shuffle=True) \n",
    " \n",
    "nb_test_samples = len(generator_top_test.filenames) \n",
    "num_classes_test = len(generator_top_test.class_indices) \n",
    "\n",
    "if includePreTrained==False:\n",
    "    # load the bottleneck features saved earlier \n",
    "    train_data = np.load(bottleneck_file_root+\"bottleneck_features_train.npy\") \n",
    "    dev_data = np.load(bottleneck_file_root+\"bottleneck_features_dev.npy\")  \n",
    "    test_data = np.load(bottleneck_file_root+\"bottleneck_features_test.npy\") \n",
    " \n",
    "test_labels = generator_top_test.classes \n",
    " \n",
    "test_labels = to_categorical(test_labels, num_classes=num_classes_test)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(train_data.shape[1:])\n",
    "vgg.summary()\n",
    "for layer in vgg.layers[:5]:\n",
    "    print(layer)\n",
    "\n",
    "print(\"======================================\")\n",
    "for layer in vgg.layers[5:]:\n",
    "    print(layer)\n",
    "# for layer in model.layers[249:]:\n",
    "#     layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Define model and start training\n",
    "start = datetime.datetime.now()\n",
    "model = Sequential() \n",
    "\n",
    "# #adding back poped 4 conv + 1 pool layer\n",
    "# print(train_data.shape[1:])\n",
    "# model.add(ZeroPadding2D((1,1),input_shape=train_data.shape[1:]))\n",
    "# model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "# model.add(ZeroPadding2D((1,1)))\n",
    "# model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "# model.add(ZeroPadding2D((1,1)))\n",
    "# model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "# model.add(ZeroPadding2D((1,1)))\n",
    "# model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "trainBool = False\n",
    "\n",
    "if includePreTrained:\n",
    "#     # Freeze the layers except the last 4 layers\n",
    "    # Check the trainable status of the individual layers\n",
    "    for layer in vgg.layers: ##[:-4]:##\n",
    "        layer.trainable = True\n",
    "#         #print(layer, layer.trainable)\n",
    "#     for layer in vgg.layers[:279]:\n",
    "#         layer.trainable = False\n",
    "#     for layer in vgg.layers[280:]:\n",
    "#         layer.trainable = True\n",
    "\n",
    "    model.add(vgg)\n",
    "    \n",
    "    if modelToLoad == \"InceptionV3\":             \n",
    "        #model.add(Flatten())\n",
    "        model.add(GlobalAveragePooling2D(name='avg_pool'))\n",
    "        model.add(Dense(1024, activation='relu'\n",
    "                        ,kernel_regularizer=regularizers.l2(0.005)\n",
    "                        #activity_regularizer=regularizers.l1(0.005)\n",
    "                       ))\n",
    "        model.add(LeakyReLU(alpha=0.3))\n",
    "        model.add(Dropout(0.6)) \n",
    "#         model.add(Dense(512, activation='relu'))\n",
    "#         model.add(LeakyReLU(alpha=0.3))\n",
    "#         model.add(Dropout(0.3)) \n",
    "        model.add(Dense(num_classes, activation='softmax', name='predictions'))\n",
    "    \n",
    "    \n",
    "        for layer in model.layers[0].layers[:-100]:\n",
    "           layer.trainable = False\n",
    "        for layer in model.layers[0].layers[-100:]:\n",
    "           layer.trainable = True\n",
    "\n",
    "        for layer in model.layers:\n",
    "            print(layer, \": \", layer.trainable)\n",
    "\n",
    "    \n",
    "        model.load_weights(\"D:/Debian/cs_230_proj/weights/inceptionv3_model_46%_[30].h5\")\n",
    "        \n",
    "#         for i in range(4):\n",
    "#             model.pop()\n",
    "\n",
    "#        model.add(Dense(1024, activation='relu'))\n",
    "#        model.add(LeakyReLU(alpha=0.3))\n",
    "#        model.add(Dropout(0.3))\n",
    "#        model.add(Dense(num_classes, activation='softmax', name='predictions'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "\n",
    "    \n",
    "#         model.add(Flatten(input_shape=train_data.shape[1:])) \n",
    "#         #FC layers\n",
    "#         model.add(Dense(256, activation='linear'))\n",
    "#         model.add(LeakyReLU(alpha=0.3))\n",
    "#         model.add(Dropout(0.5)) \n",
    "#         model.add(Dense(128, activation='linear'))\n",
    "#         model.add(LeakyReLU(alpha=0.3))\n",
    "#         model.add(Dropout(0.3)) \n",
    "#         model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "    \n",
    "    elif modelToLoad == \"VGG\":\n",
    "        model.add(Flatten()) \n",
    "        #FC layers\n",
    "        model.add(Dense(256, activation='linear'))\n",
    "        model.add(LeakyReLU(alpha=0.3))\n",
    "        model.add(Dropout(0.5)) \n",
    "        model.add(Dense(128, activation='linear'))\n",
    "        model.add(LeakyReLU(alpha=0.3))\n",
    "        model.add(Dropout(0.3)) \n",
    "        model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    #     #https://gist.github.com/didacroyo/839bd1dbb67463df8ba8fb14eb3fde0c\n",
    "#     # we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "#     # the first 249 layers and unfreeze the rest:\n",
    "#     # in other examples found it was 172 insted 249. \n",
    "#     # I took 249 according to https://keras.io/applications/#inceptionv3\n",
    "#     for layer in model.layers[:280]:\n",
    "#         layer.trainable = False\n",
    "#     for layer in model.layers[280:]:\n",
    "#         layer.trainable = True\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "else:\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:])) \n",
    "    #FC layers\n",
    "    model.add(Dense(256, activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(Dropout(0.5)) \n",
    "    model.add(Dense(128, activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(Dropout(0.3)) \n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "for layer in vgg.layers:\n",
    "    print(layer, layer.trainable)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "    #optimizer=optimizers.Adam(lr=2e-4),#optimizers.RMSprop(lr=1e-4),\n",
    "    optimizer=optimizers.SGD(momentum=0.8, lr=1e-5),#decay=1e-2/epochs\n",
    "    #optimizer=optimizers.RMSprop(),\n",
    "    metrics=[\"acc\"])\n",
    "print(\"debug \" , predict_size_train)\n",
    "if trainBool:\n",
    "    if includePreTrained:\n",
    "        history = model.fit_generator(generator_top, \n",
    "                                      steps_per_epoch=predict_size_train,\n",
    "                                      validation_data=generator_top_dev, \n",
    "                                      validation_steps=predict_size_dev, \n",
    "                                      epochs = epochs, \n",
    "                                      class_weight = class_weights,\n",
    "                                      verbose = 1,\n",
    "                                      #use_multiprocessing=True,\n",
    "                                      max_queue_size=6,\n",
    "                                      workers=6\n",
    "    #                                   callbacks=[EarlyStopping(monitor='val_acc', \n",
    "    #                                                            min_delta=0.0001, \n",
    "    #                                                            patience=5, \n",
    "    #                                                            verbose=1, \n",
    "    #                                                            mode='auto', \n",
    "    #                                                            baseline=None, \n",
    "    #                                                            restore_best_weights=True\n",
    "    #                                                           )]\n",
    "                                     )\n",
    "\n",
    "        model.save_weights(top_model_weights_path)\n",
    "\n",
    "        (eval_loss, eval_accuracy) = model.evaluate_generator(generator_top_dev, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=1)\n",
    "\n",
    "    else:\n",
    "        #To use npy input\n",
    "        history = model.fit(train_data, train_labels, \n",
    "           epochs=epochs,\n",
    "           batch_size=train_batch_size, \n",
    "           validation_data=(dev_data, dev_labels))\n",
    "\n",
    "        model.save_weights(top_model_weights_path)\n",
    "\n",
    "        (eval_loss, eval_accuracy) = model.evaluate( \n",
    "            dev_data, dev_labels, batch_size=dev_batch_size,verbose=1)\n",
    "\n",
    "    print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100)) \n",
    "    print(\"[INFO] Loss: {}\".format(eval_loss)) \n",
    "\n",
    "    end= datetime.datetime.now()\n",
    "    elapsed= end-start\n",
    "    print (\"Time: \", elapsed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "        print(layer, layer.trainable)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Graphing training and validation results\n",
    "def plotTraining(history):\n",
    "    acc = history.history[\"acc\"]\n",
    "    val_acc = history.history[\"val_acc\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(len(acc))\n",
    "    plt.plot(epochs, acc, \"r\", label=\"Training acc\")\n",
    "    plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
    "    plt.title(\"Training and validation accuracy\")\n",
    "    plt.ylabel(\"accuracy\") \n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, \"r\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.ylabel(\"loss\") \n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotTraining(history)\n",
    "\n",
    "##Evaluate on test set\n",
    "print(model.metrics_names)\n",
    "if includePreTrained:\n",
    "#     print(model.evaluate_generator(generator_top_test, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=1))\n",
    "    print(model.evaluate_generator(generator_top_test, steps=predict_size_test, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=1))\n",
    "\n",
    "    #predict_generator(generator_top_test, steps=predict_size_test,verbose=1)\n",
    "# else:\n",
    "#     model.evaluate(test_data,test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TOP K accuracy###\n",
    "import functools\n",
    "from keras import metrics as M\n",
    "top3_acc = functools.partial(M.top_k_categorical_accuracy, k=3)\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "    optimizer= optimizers.SGD(momentum=0.8, lr=1e-4, decay=1e-2/epochs),\n",
    "    #optimizers.Adam(lr=2e-4),#optimizers.RMSprop(lr=1e-4),\n",
    "    #optimizer=optimizers.SGD(momentum=0.8, lr=1e-3, decay=1e-2/epochs),#decay=1e-2/epochs\n",
    "    #optimizer=optimizers.RMSprop(),\n",
    "    metrics=[\"acc\",'top_k_categorical_accuracy',top3_acc])\n",
    "model.load_weights(\"D:\\Debian\\cs_230_proj\\weights\\inceptionv3_model_46%_[30].h5\")\n",
    "print(model.metrics_names)\n",
    "model.evaluate_generator(generator_top_test, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Draw Confusion Matrix:\n",
    "def plot_confusion_matrix(cm1, classes,\n",
    "   normalize=False,\n",
    "   title=\"Confusion matrix\",\n",
    "   cmap=plt.cm.Blues):\n",
    " \n",
    "#Add Normalization Option\n",
    "#  prints pretty confusion metric with normalization option \n",
    "   if normalize:\n",
    "     cm = cm1.astype('float') / cm1.sum(axis=1)[:, np.newaxis]\n",
    "     print(\"Normalized confusion matrix\")\n",
    "   else:\n",
    "     print(\"Confusion matrix, without normalization\")\n",
    " \n",
    "# print(cm)\n",
    " \n",
    "   plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "   plt.title(title)\n",
    "   plt.colorbar()\n",
    "   tick_marks = np.arange(len(classes))\n",
    "   plt.xticks(tick_marks, classes, rotation=45)\n",
    "   plt.yticks(tick_marks, classes)\n",
    " \n",
    "   fmt = \".2f\" if normalize else \"d\"\n",
    "   thresh = cm.max() / 2.\n",
    "   for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "      plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "   plt.tight_layout()\n",
    "   plt.ylabel(\"True label\")\n",
    "   plt.xlabel(\"Predicted label\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=== To perform error analysis by examing the correctly or incorrectly labeled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion to display correctly or incorrectly predicted pictures\n",
    "def display_images(set,path):\n",
    "    # Show the set\n",
    "    for i in range(len(set)):\n",
    "        pred_class = np.argmax(predictions[set[i]])\n",
    "        pred_label = idx2label[pred_class]\n",
    "\n",
    "        title = 'Original label:{}, Prediction :{}, confidence : {:.3f}'.format(\n",
    "            fnames[set[i]].split('/')[0],\n",
    "            pred_label,\n",
    "            predictions[set[i]][pred_class])\n",
    "\n",
    "        original = load_img('{}/{}'.format(path,fnames[set[i]]))\n",
    "        plt.figure(figsize=[7,7])\n",
    "        plt.axis('off')\n",
    "        plt.title(title)\n",
    "        plt.imshow(original)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Combine frozen layers and trained layers to form the final full model \n",
    "num_classes = 605\n",
    "vgg = InceptionV3(include_top=False, weights=\"imagenet\",input_shape=(image_size_w, image_size_h, 3))\n",
    "\n",
    "full_model = Sequential()\n",
    "full_model.add(vgg)\n",
    "full_model.add(GlobalAveragePooling2D(name='avg_pool'))\n",
    "full_model.add(Dense(1024, activation='relu'\n",
    "                ,kernel_regularizer=regularizers.l2(0.005)\n",
    "                #activity_regularizer=regularizers.l1(0.005)\n",
    "               ))\n",
    "full_model.add(LeakyReLU(alpha=0.3))\n",
    "full_model.add(Dropout(0.6)) \n",
    "#         model.add(Dense(512, activation='relu'))\n",
    "#         model.add(LeakyReLU(alpha=0.3))\n",
    "#         model.add(Dropout(0.3)) \n",
    "full_model.add(Dense(num_classes, activation='softmax', name='predictions'))\n",
    "\n",
    "full_model.load_weights(\"D:/Debian/cs_230_proj/weights/inceptionv3_model_45%_[29].h5\")\n",
    "\n",
    "full_model.compile(loss=\"categorical_crossentropy\",\n",
    "    #optimizer=optimizers.Adam(lr=2e-4),#optimizers.RMSprop(lr=1e-4),\n",
    "    optimizer=optimizers.SGD(momentum=0.8, lr=1e-4, decay=1e-2/epochs),#decay=1e-2/epochs\n",
    "    #optimizer=optimizers.RMSprop(),\n",
    "    metrics=[\"acc\"])\n",
    "# print(full_model.summary())\n",
    "\n",
    "# Create a generator for prediction\n",
    "datagen_test = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "generator_top_test = datagen_test.flow_from_directory( \n",
    "   test_path, \n",
    "   target_size=(image_size_w, image_size_h), \n",
    "   batch_size=test_batch_size, \n",
    "   class_mode=\"categorical\", \n",
    "   shuffle=False) \n",
    "\n",
    "# print(full_model.evaluate_generator(generator_top_test, steps=predict_size_test, verbose=1))\n",
    "\n",
    "\n",
    "# Get the filenames from the generator\n",
    "fnames = generator_top_test.filenames\n",
    " \n",
    "# Get the ground truth from generator\n",
    "ground_truth  = generator_top_test.classes\n",
    " \n",
    "# Get the label to class mapping from the generator\n",
    "label2index = generator_top_test.class_indices\n",
    " \n",
    "# Getting the mapping from class index to class label\n",
    "idx2label = dict((v,k) for k,v in label2index.items())   \n",
    "\n",
    "\n",
    "# # # Get the predictions from the model using the generator\n",
    "generator_top_test.reset()\n",
    "predictions = full_model.predict_generator(generator_top_test, steps=predict_size_test,verbose=1)\n",
    "# # classes = generator_top_test.classes[generator_top_test.index_array]\n",
    "predicted_classes  = np.argmax(predictions, axis=-1)\n",
    "# # print(sum(predicted_classes==classes)/11622)\n",
    "\n",
    "# # to get one batch of images and labels\n",
    "# y_img_batch, y_class_batch = generator_top_test[1] \n",
    "# y_pred = np.argmax(full_model.predict(y_img_batch),-1)\n",
    "# y_true = np.argmax(y_class_batch,-1)\n",
    "# print(sum(y_pred==y_true)/test_batch_size)\n",
    "# print(test_batch_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# y_pred = full_model.predict_generator(generator_top_test, steps=predict_size_test,verbose=1)\n",
    "# y_true = np.argmax(predictions,axis=1)    \n",
    " \n",
    "errors = np.where(predicted_classes != ground_truth )[0]\n",
    "corrects = np.where(predicted_classes  == ground_truth )[0]\n",
    "\n",
    "print(\"No of errors = {}/{}\".format(len(errors),generator_top_test.samples)) \n",
    "print(\"No of corrects = {}/{}\".format(len(corrects),generator_top_test.samples))\n",
    "# print(\"====Errors=====\")\n",
    "# display_images(errors,test_path)\n",
    "# print(\"====Corrects=====\")\n",
    "# display_images(corrects,test_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "generator_top_test.reset()\n",
    "# #model.evaluate(test_data,test_labels)\n",
    "# Y_pred = model.predict_generator(generator_top_test, verbose=1)\n",
    "# #preds = np.round(model.predict(test_data),0)\n",
    "# preds = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "#print(confusion_matrix(np.argmax(test_labels,axis=1).tolist(), np.argmax(preds, axis=1).tolist()))\n",
    "print(confusion_matrix(generator_top_test.classes, predicted_classes))\n",
    "print('Classification Report')\n",
    "target_names = os.listdir(train_path)\n",
    "print(classification_report(generator_top_test.classes, predicted_classes, target_names=target_names))\n",
    "\n",
    "\n",
    "# print('rounded test_labels',preds)\n",
    "# classesList = os.listdir(train_path)\n",
    "# classification_metrics = metrics.classification_report(test_labels,preds,target_names=classesList)\n",
    "# print(classification_metrics)\n",
    "\n",
    "#cm2 = confusion_matrix(np.argmax(test_labels,axis=1).tolist(), predicted_classes.tolist())\n",
    "cm2 = confusion_matrix(generator_top_test.classes[:10], predicted_classes[:10])\n",
    "plot_confusion_matrix(cm2,\n",
    "                     generator_top_test.classes[:10],\n",
    "                     normalize=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the errors\n",
    "array = errors\n",
    "error_makemodel = 0\n",
    "for i in range(len(array)):\n",
    "    r = np.random.randint(0,len(array))\n",
    "    #r = i\n",
    "    pred_class = np.argmax(predictions[array[r]])\n",
    "    pred_label = idx2label[pred_class]\n",
    "    \n",
    "    actual_makemodel = fnames[array[r]].split('/')[0]\n",
    "    actual_makemodel = actual_makemodel.split('_')[0] + \"_\" + actual_makemodel.split('_')[1]\n",
    "    \n",
    "    pred_makemodel = pred_label.split('_')[0] + \"_\" + pred_label.split('_')[1]\n",
    "    if pred_makemodel != actual_makemodel:\n",
    "        print(\"pred: \", pred_makemodel, \"actual: \", actual_makemodel)\n",
    "        error_makemodel += 1\n",
    "        title = 'Original label:{}, Prediction :{}, confidence : {:.3f}'.format(\n",
    "            fnames[array[r]].split('/')[0],\n",
    "            pred_label,\n",
    "            predictions[array[r]][pred_class])\n",
    "\n",
    "        original = load_img('{}/{}'.format(test_path,fnames[array[r]]))\n",
    "        plt.figure(figsize=[7,7])\n",
    "        plt.axis('off')\n",
    "        plt.title(title)\n",
    "        plt.imshow(original)\n",
    "        plt.show()\n",
    "print(error_makemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test to load and modify models from .h5\n",
    "loadModel = Sequential()\n",
    "\n",
    "loadModel.add(vgg)\n",
    "\n",
    "#model.add(Flatten())\n",
    "loadModel.add(GlobalAveragePooling2D(name='avg_pool'))\n",
    "loadModel.add(Dense(1024, activation='relu'\n",
    "                ,kernel_regularizer=regularizers.l2(0.005)\n",
    "                #activity_regularizer=regularizers.l1(0.005)\n",
    "               ))\n",
    "loadModel.add(LeakyReLU(alpha=0.3))\n",
    "loadModel.add(Dropout(0.5)) \n",
    "loadModel.add(Dense(512, activation='relu'))\n",
    "loadModel.add(LeakyReLU(alpha=0.3))\n",
    "loadModel.add(Dropout(0.3)) \n",
    "loadModel.add(Dense(num_classes, activation='softmax', name='predictions'))\n",
    "\n",
    "loadModel.load_weights(\"D:\\Debian\\cs_230_proj\\inceptionv3_model_top40-66%_[16-4].h5\")\n",
    "loadModel.summary()\n",
    "\n",
    "# for i in range(4):\n",
    "#     loadModel.pop()\n",
    "\n",
    "# loadModel.add(Dense(1024, activation='relu'))\n",
    "# loadModel.add(LeakyReLU(alpha=0.3))\n",
    "# loadModel.add(Dropout(0.3)) \n",
    "# loadModel.add(Dense(604, activation='softmax', name='predictions'))\n",
    "\n",
    "# loadModel.summary()\n",
    "\n",
    "# for layer in loadModel.layers[:-8]:\n",
    "#     layer.trainable = False\n",
    "# for layer in loadModel.layers[-7:]:\n",
    "#     layer.trainable = True\n",
    "    \n",
    "# for layer in loadModel.layers:\n",
    "#     print(layer, \": \", layer.trainable)\n",
    "\n",
    "# for layers in loadModel.layers[0].layers:\n",
    "#     print(layers)\n",
    "# print(loadModel.layers[0])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To visualize Filters and Features\n",
    "#https://towardsdatascience.com/visualising-filters-and-feature-maps-for-deep-learning-d814e13bd671\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "full_model = Sequential()\n",
    "full_model.add(vgg)\n",
    "full_model.add(GlobalAveragePooling2D(name='avg_pool'))\n",
    "full_model.add(Dense(1024, activation='relu'\n",
    "                ,kernel_regularizer=regularizers.l2(0.005)\n",
    "                #activity_regularizer=regularizers.l1(0.005)\n",
    "               ))\n",
    "full_model.add(LeakyReLU(alpha=0.3))\n",
    "full_model.add(Dropout(0.6)) \n",
    "#         model.add(Dense(512, activation='relu'))\n",
    "#         model.add(LeakyReLU(alpha=0.3))\n",
    "#         model.add(Dropout(0.3)) \n",
    "full_model.add(Dense(num_classes, activation='softmax', name='predictions'))\n",
    "\n",
    "full_model.load_weights(\"D:/Debian/cs_230_proj/weights/inceptionv3_model_45%_[29].h5\")\n",
    "\n",
    "full_model.compile(loss=\"categorical_crossentropy\",\n",
    "    #optimizer=optimizers.Adam(lr=2e-4),#optimizers.RMSprop(lr=1e-4),\n",
    "    optimizer=optimizers.SGD(momentum=0.8, lr=1e-4, decay=1e-2/epochs),#decay=1e-2/epochs\n",
    "    #optimizer=optimizers.RMSprop(),\n",
    "    metrics=[\"acc\"])\n",
    "full_model.summary()\n",
    "layer_dict = dict([(layer.name, layer) for layer in full_model.layers])\n",
    "\n",
    "layer_name = 'inception_v3'\n",
    "# for _ in range(4):\n",
    "#     full_model.pop()\n",
    "\n",
    "full_model.summary()\n",
    "# model = Model(inputs=full_model.inputs, output = layer_dict.get_output_at(0)) #outputs=layer_dict[layer_name].output)\n",
    "\n",
    "# Perpare the image\n",
    "image = load_img('D:/Debian/cs_230_proj/VMMRdb_year2000+_sample100+/test/acura_mdx_2001/2001 acura mdx_01212_5kttdWUTmZQ_600x450.jpg', target_size=(image_size_w, image_size_h))\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "image = preprocess_input(image)\n",
    "\n",
    "# Apply the model to the image\n",
    "feature_maps = full_model.predict(image)\n",
    "\n",
    "square = 8\n",
    "index = 1\n",
    "for _ in range(square):\n",
    "\tfor _ in range(square):\n",
    "        \n",
    "\t\tax = plt.subplot(square, square, index)\n",
    "\t\tax.set_xticks([])\n",
    "\t\tax.set_yticks([])\n",
    "\n",
    "\t\tplt.imshow(feature_maps[0, :, :, index-1], cmap='viridis')\n",
    "\t\tindex += 1\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##From: https://github.com/molohov/cs230-project/blob/master/dev/visualize_nn_layer.py##\n",
    "from keras import backend as K\n",
    "from vis.losses import ActivationMaximization\n",
    "from vis.regularizers import TotalVariation, LPNorm\n",
    "import numpy as np\n",
    "from vis.visualization import visualize_activation\n",
    "from vis.visualization import get_num_filters\n",
    "from vis.utils import utils\n",
    "from keras import activations\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "#from scipy.misc import imresize\n",
    "\n",
    "from PIL import Image\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, Input, BatchNormalization, Conv2D\n",
    "from vis.input_modifiers import Jitter\n",
    "\n",
    "\n",
    "## you must install this version of keras-vis from the repo in order for this to work\n",
    "## pip install git+https://github.com/raghakot/keras-vis.git --upgrade\n",
    "\n",
    "## otherwise you'll get this weird error\n",
    "## tensorflow.python.framework.errors_impl.InvalidArgumentError: input_1:0 is both fed and fetched.\n",
    "\n",
    "\n",
    "\n",
    "# load model\n",
    "model = full_model.layers[0]\n",
    "#model = InceptionV3(weights='imagenet', include_top=False, input_tensor=Input(shape=(150, 150, 3)))\n",
    "print('Model loaded.')\n",
    "#model.summary()\n",
    "single_filter = False\n",
    "#single_filter = True\n",
    "\n",
    "model.summary()\n",
    "# The name of the layer we want to visualize\n",
    "layer_name = 'conv2d_1'\n",
    "layer_idx = utils.find_layer_idx(model, layer_name)\n",
    "\n",
    "# Visualize all filters in this layer.\n",
    "filters = None\n",
    "if (single_filter == False):\n",
    "    filters = np.arange(get_num_filters(model.layers[layer_idx]))\n",
    "else:\n",
    "    filters = ([0])\n",
    "\n",
    "# Generate input image for each filter.\n",
    "vis_images = []\n",
    "print (\"Processing \", len(filters), \" filters\")\n",
    "for idx in filters:\n",
    "    print (\"Processing filter\", idx, \"/\", len(filters))\n",
    "    img = visualize_activation(model, layer_idx, filter_indices=idx, tv_weight=0., max_iter=100, input_modifiers=[Jitter(0.05)])\n",
    "\n",
    "    # Utility to overlay text on image.\n",
    "    img = utils.draw_text(img, 'Filter {}'.format(idx))    \n",
    "    vis_images.append(img)\n",
    "\n",
    "# Generate stitched image palette with 8 cols.\n",
    "stitched = utils.stitch_images(vis_images, cols=8)    \n",
    "plt.axis('off')\n",
    "plt.title(layer_name)\n",
    "plt.imsave(layer_name + \".png\", stitched)\n",
    "#plt.imshow(stitched)\n",
    "#plt.show()\n",
    "#stitched = Image.fromarray(stitched)\n",
    "#stitched.save(layer_name + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert Sequential model to function\n",
    "input_layer = layers.Input(batch_shape=full_model.layers[0].input_shape)\n",
    "prev_layer = input_layer\n",
    "for layer in full_model.layers:\n",
    "    layer._inbound_nodes = []\n",
    "    prev_layer = layer(prev_layer)\n",
    "\n",
    "funcmodel = models.Model([input_layer], [prev_layer])\n",
    "funcmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://edebrouwer.github.io/deeplearning/carvision/visualization/neural/networks/learning/2017/08/09/Deep_Visualization.html\n",
    "from vis.visualization import visualize_activation,visualize_saliency,overlay,visualize_cam\n",
    "from vis.utils import utils\n",
    "from keras import activations\n",
    "from keras import models\n",
    "\n",
    "full_model = Sequential()\n",
    "base_model = InceptionV3(weights='imagenet',include_top=False,input_shape = (299, 299, 3))\n",
    "\n",
    "full_model.add(base_model)\n",
    "full_model.add(GlobalAveragePooling2D(name='avg_pool'))\n",
    "full_model.add(Dense(1024, activation='relu'\n",
    "                ,kernel_regularizer=regularizers.l2(0.005)\n",
    "                #activity_regularizer=regularizers.l1(0.005)\n",
    "               ))\n",
    "full_model.add(LeakyReLU(alpha=0.3))\n",
    "full_model.add(Dropout(0.6)) \n",
    "#         model.add(Dense(512, activation='relu'))\n",
    "#         model.add(LeakyReLU(alpha=0.3))\n",
    "#         model.add(Dropout(0.3)) \n",
    "full_model.add(Dense(num_classes, activation='softmax', name='predictions'))\n",
    "\n",
    "full_model.load_weights(\"D:/Debian/cs_230_proj/weights/inceptionv3_model_45%_[29].h5\")\n",
    "\n",
    "# full_model.layers[0].summary()\n",
    "\n",
    "new_model = Sequential()\n",
    "for layer in full_model.layers[0].layers:\n",
    "    new_model.add(layer)\n",
    "    print(layers)\n",
    "\n",
    "\n",
    "print(len(full_model.get_weights()))\n",
    "# full_model.compile(loss=\"categorical_crossentropy\",\n",
    "#     #optimizer=optimizers.Adam(lr=2e-4),#optimizers.RMSprop(lr=1e-4),\n",
    "#     optimizer=optimizers.SGD(momentum=0.8, lr=1e-4, decay=1e-2/epochs),#decay=1e-2/epochs\n",
    "#     #optimizer=optimizers.RMSprop(),\n",
    "#     metrics=[\"acc\"])\n",
    "\n",
    "# base_model = InceptionV3(weights='imagenet',include_top=False,input_shape = (299, 299, 3))\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "\n",
    "# #Only for version 2:\n",
    "# x = Dense(1024, activation='relu'\n",
    "#                 ,kernel_regularizer=regularizers.l2(0.005))(x)\n",
    "# x = LeakyReLU(alpha=0.3)(x)\n",
    "# x = Dropout(0.6)(x)\n",
    "# predictions = Dense(num_classes, activation='softmax',name='predictions')(x)\n",
    "\n",
    "# func_model= Model(inputs=base_model.input, outputs=predictions)\n",
    "# print(\"layer counter: \",len(func_model.layers))\n",
    "# func_model.summary()\n",
    "# func_model.load_weights(\"D:/Debian/cs_230_proj/weights/inceptionv3_model_45%_[29].h5\", by_name=True)\n",
    "# #model_origin = InceptionV3(weights='imagenet', include_top=True)\n",
    "# func_model.compile(loss=\"categorical_crossentropy\",\n",
    "#     #optimizer=optimizers.Adam(lr=2e-4),#optimizers.RMSprop(lr=1e-4),\n",
    "#     optimizer=optimizers.SGD(momentum=0.8, lr=1e-4, decay=1e-2/epochs),#decay=1e-2/epochs\n",
    "#     #optimizer=optimizers.RMSprop(),\n",
    "#     metrics=[\"acc\"])\n",
    "# print(func_model.evaluate_generator(generator_top_test, steps=predict_size_test, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=1))\n",
    "\n",
    "\n",
    "\n",
    "# Utility to search for layer index by name.\n",
    "# Alternatively we can specify this as -1 since it corresponds to the last layer.\n",
    "layer_idx = utils.find_layer_idx(full_model, 'predictions')\n",
    "print(\"Remove Activation from Last Layer\")\n",
    "# Swap softmax with linear\n",
    "full_model.layers[layer_idx].activation = activations.linear\n",
    "print(\"Done. Now Applying changes to the model ...\")\n",
    "full_model = utils.apply_modifications(full_model)\n",
    "im_files=[\"D:/Debian/cs_230_proj/VMMRdb_year2000+_sample100+/test/chevrolet_silverado_2014/2014 chevrolet 1500 silverado_00J0J_aNCzTaQOp4n_600x450.jpg\"]\n",
    "for im_file in im_files:\n",
    "    img1 = image.load_img(im_file,target_size=(299,299))\n",
    "    img1 = image.img_to_array(img1)\n",
    "    img1 = np.expand_dims(img1, axis=0)\n",
    "    img1 = preprocess_input(img1)\n",
    "    layer_idx = utils.find_layer_idx(full_model, 'predictions')\n",
    "    heatmap = visualize_cam(full_model, layer_idx, filter_indices=1, seed_input=img1[0,:,:,:])\n",
    "    img_init=utils.load_img(im_file,target_size=(299,299))\n",
    "    plt.imshow(overlay(img_init, heatmap))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from matplotlib import pyplot\n",
    "\n",
    "vgg = InceptionV3(include_top=False, weights=\"imagenet\",input_shape=(image_size_w, image_size_h, 3))\n",
    "\n",
    "\n",
    "full_model = Sequential()\n",
    "full_model.add(vgg)\n",
    "full_model.add(GlobalAveragePooling2D(name='avg_pool'))\n",
    "full_model.add(Dense(1024, activation='relu'\n",
    "                ,kernel_regularizer=regularizers.l2(0.005)\n",
    "                #activity_regularizer=regularizers.l1(0.005)\n",
    "               ))\n",
    "full_model.add(LeakyReLU(alpha=0.3))\n",
    "full_model.add(Dropout(0.6)) \n",
    "#         model.add(Dense(512, activation='relu'))\n",
    "#         model.add(LeakyReLU(alpha=0.3))\n",
    "#         model.add(Dropout(0.3)) \n",
    "full_model.add(Dense(605, activation='softmax', name='predictions'))\n",
    "\n",
    "full_model.load_weights(\"D:/Debian/cs_230_proj/weights/inceptionv3_model_45%_[29].h5\")\n",
    "####################\n",
    "### Plot filters ###\n",
    "###################\n",
    "# for layer in full_model.layers[0].layers:\n",
    "#     # check for convolutional layer\n",
    "#     if 'conv' not in layer.name:\n",
    "#         continue\n",
    "#     # get filter weights\n",
    "#     filters = layer.get_weights()[0]\n",
    "#     print(layer.name, filters.shape)\n",
    "  \n",
    "#     # normalize filter values to 0-1 so we can visualize them\n",
    "#     f_min, f_max = filters.min(), filters.max()\n",
    "#     filters = (filters - f_min) / (f_max - f_min)\n",
    "\n",
    "#     # plot first few filters\n",
    "#     n_filters, ix = 6, 1\n",
    "#     for i in range(n_filters):\n",
    "#         # get the filter\n",
    "#         f = filters[:, :, :, i]\n",
    "#         # plot each channel separately\n",
    "#         for j in range(3):\n",
    "#             # specify subplot and turn of axis\n",
    "#             ax = pyplot.subplot(n_filters, 3, ix)\n",
    "#             ax.set_xticks([])\n",
    "#             ax.set_yticks([])\n",
    "#             # plot filter channel in grayscale\n",
    "#             pyplot.imshow(f[:, :, j], cmap='gray')\n",
    "#             ix += 1\n",
    "#     # show the figure\n",
    "#     pyplot.show()\n",
    "\n",
    "#####################\n",
    "## Plot Feature Map##\n",
    "#####################\n",
    "# summarize feature map shapes\n",
    "conv_idx_array = []\n",
    "inv3_model = full_model.layers[0]\n",
    "for i in range(len(inv3_model.layers)):\n",
    "    layer = inv3_model.layers[i]\n",
    "    # check for convolutional layer\n",
    "    if 'conv' not in layer.name:\n",
    "        continue\n",
    "    # summarize output shape\n",
    "    conv_idx_array.append(i)\n",
    "    print(i, layer.name, layer.output.shape, layer.output.shape[3])\n",
    "print(\"sum of output = \", np.sum(conv_idx_array))\n",
    "# load the image with the required shape\n",
    "img = load_img('D:/Debian/cs_230_proj/VMMRdb/volkswagen_gti_2015/2015 volkswagen gti_01111_jBKFWm6SB9U_600x450.jpg', target_size=(299, 299))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "# convert the image to an array\n",
    "img = img_to_array(img)\n",
    "# expand dimensions so that it represents a single 'sample'\n",
    "img = np.expand_dims(img, axis=0)\n",
    "# prepare the image (e.g. scale pixel values for the vgg)\n",
    "img = preprocess_input(img)\n",
    "\n",
    "for convIdx in conv_idx_array:\n",
    "    # redefine model to output right after the first hidden layer\n",
    "    model = Model(inputs=inv3_model.inputs, outputs=inv3_model.layers[convIdx].output)\n",
    "    # get feature map for first hidden layer\n",
    "    feature_maps = model.predict(img)\n",
    "    # plot all 64 maps in an 8x8 squares\n",
    "    square = 8\n",
    "    ix = 1\n",
    "    layerName = inv3_model.layers[convIdx].name\n",
    "    #layerName = layerName.split(\"_\")[0] + \"_\" + str(int(layerName.split(\"_\")[1]) - 84)\n",
    "    print(layerName)\n",
    "    pyplot.figure(figsize = (20,20))\n",
    "    for _ in range(square):\n",
    "        for _ in range(square):\n",
    "            if ix <= inv3_model.layers[convIdx].output.shape[3]:\n",
    "                # specify subplot and turn of axis\n",
    "                ax = pyplot.subplot(square, square, ix)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                # plot filter channel in grayscale\n",
    "                pyplot.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n",
    "                ix += 1\n",
    "    # show the figure\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=====Below code is for references only====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# classesList = os.listdir(train_path)\n",
    "# print(classesList)\n",
    "# class_size = len(classesList)\n",
    "# # datagen = ImageDataGenerator(rescale=1./255)\n",
    "# # generator = datagen.flow_from_directory(\n",
    "# #     train_path,\n",
    "# #     target_size=(image_size_h, image_size_w), \n",
    "# #     #classes=classesList, \n",
    "# #     class_mode=None,\n",
    "# #     batch_size=train_batch_size\n",
    "# #     #color_mode='grayscale'\n",
    "# # )\n",
    "\n",
    "\n",
    "\n",
    "# train_batches = ImageDataGenerator(\n",
    "#     rescale=1./255,\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     vertical_flip=True,\n",
    "#     fill_mode='nearest'\n",
    "# ).flow_from_directory(\n",
    "#     train_path, \n",
    "#     target_size=(image_size_h, image_size_w), \n",
    "#     classes=classesList, \n",
    "#     batch_size=train_batch_size\n",
    "#     #color_mode='grayscale'\n",
    "# )\n",
    "\n",
    "# dev_batches = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "#     dev_path, \n",
    "#     target_size=(image_size_h, image_size_w), \n",
    "#     classes=classesList, \n",
    "#     batch_size=dev_batch_size\n",
    "#     #color_mode='grayscale'\n",
    "# #     class_mode=None\n",
    "# )\n",
    "\n",
    "# test_batches = ImageDataGenerator().flow_from_directory(\n",
    "#     test_path, \n",
    "#     target_size=(image_size_h, image_size_w), \n",
    "#     #classes=classesList, \n",
    "#     batch_size=test_batch_size\n",
    "#    # color_mode='grayscale'\n",
    "# )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #source: https://github.com/smileservices/keras_utils/blob/master/utils.py\n",
    "# # plots images with labels within jupyter notebook\n",
    "# def plots(ims, figsize=(60,30), rows=2, interp=False, titles=None):\n",
    "#     if type(ims[0]) is np.ndarray:\n",
    "#         ims = np.array(ims).astype(np.uint8)\n",
    "#         if (ims.shape[-1] != 3):\n",
    "#             ims = ims.transpose((0,2,3,1))\n",
    "#     f = plt.figure(figsize=figsize)\n",
    "#     cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "#     for i in range(len(ims)):\n",
    "#         sp = f.add_subplot(rows, cols, i+1)\n",
    "#         sp.axis('Off')\n",
    "#         if titles is not None:\n",
    "#             sp.set_title(titles[i], fontsize=16)\n",
    "#         plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imgs,labels= next(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(imgs.shape)\n",
    "# plots(imgs,titles=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Load the VGG model\n",
    "# vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(image_size_h, image_size_w, 3))\n",
    "\n",
    "# for layer in vgg_conv.layers[:-4]:\n",
    "#     layer.trainable = False\n",
    "# for layer in vgg_conv.layers:\n",
    "#     print(layer)\n",
    "\n",
    "# # model =Sequential([\n",
    "# #     Conv2D(32,(3,3),activation='relu',input_shape=(382,512,3)),\n",
    "# #     Flatten(),\n",
    "# #     Dense(8,activation='softmax'),\n",
    "# # ])\n",
    "# # model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "# # model.fit_generator(train_batches, steps_per_epoch=34,validation_data=dev_batches, validation_steps=4, epochs = 5, verbose = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #define the model\n",
    "# model= Sequential([\n",
    "#     vgg_conv,\n",
    "#     Flatten(),\n",
    "#     Dense(512,activation='relu'),\n",
    "#     Dropout(0.8),\n",
    "#     Dense(class_size, activation='softmax')\n",
    "# ])\n",
    "# model.summary()\n",
    "\n",
    "# optimizer = optimizers.Adam()#lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==References Code End==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
